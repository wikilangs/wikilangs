---
import BaseLayout from '@layouts/BaseLayout.astro';
---

<BaseLayout
  title="Research"
  description="Research methodology, metrics glossary, and evaluation approach for Wikilangs NLP models."
>
  <section class="hero-compact">
    <div class="container">
      <h1>Research & Methodology</h1>
      <p class="hero-subtitle">
        Understanding the pipeline, metrics, and evaluation methods behind Wikilangs.
      </p>
    </div>
  </section>

  <!-- Navigation -->
  <nav class="section-nav">
    <div class="container">
      <a href="#pipeline" class="nav-link">
        <span class="nav-icon">‚öôÔ∏è</span>
        <span>
          <strong>Pipeline</strong>
          <small>How we build models</small>
        </span>
      </a>
      <a href="#evaluation" class="nav-link">
        <span class="nav-icon">üìä</span>
        <span>
          <strong>Evaluation</strong>
          <small>Metrics & interpretation</small>
        </span>
      </a>
    </div>
  </nav>

  <!-- ====== PART 1: PIPELINE METHODOLOGY ====== -->
  <section class="section" id="pipeline">
    <div class="container">
      <div class="section-header">
        <span class="section-badge">Part 1</span>
        <h2>Pipeline Methodology</h2>
        <p class="section-subtitle">How we transform Wikipedia dumps into trained models and evaluation reports</p>
      </div>

      <div class="pipeline-flow">
        <div class="pipeline-step">
          <div class="step-number">1</div>
          <div class="step-content">
            <h3>Data Collection</h3>
            <p>
              We use <a href="https://huggingface.co/datasets/omarkamali/wikipedia-monthly" target="_blank" rel="noopener">wikipedia-monthly</a>,
              a regularly updated dataset containing Wikipedia articles across 340+ languages. Monthly snapshots ensure reproducibility and allow tracking language evolution over time.
            </p>
            <div class="step-details">
              <span class="detail-badge">340+ Languages</span>
              <span class="detail-badge">Monthly Updates</span>
              <span class="detail-badge">Reproducible</span>
            </div>
          </div>
        </div>

        <div class="pipeline-step">
          <div class="step-number">2</div>
          <div class="step-content">
            <h3>Text Processing</h3>
            <p>
              Raw Wikipedia text undergoes cleaning (removing markup, citations, tables) and normalization.
              We preserve linguistic features like scripts, diacritics, and punctuation important for each language.
            </p>
            <div class="step-details">
              <span class="detail-badge">Script Preservation</span>
              <span class="detail-badge">Normalization</span>
            </div>
          </div>
        </div>

        <div class="pipeline-step">
          <div class="step-number">3</div>
          <div class="step-content">
            <h3>Model Training</h3>
            <p>For each language, we train multiple model types with systematic hyperparameter variations:</p>
            <ul class="model-list">
              <li><strong>Tokenizers (BPE)</strong> ‚Äî 8k, 16k, 32k, 64k vocabulary sizes</li>
              <li><strong>N-gram models</strong> ‚Äî 2-gram through 5-gram, word and subword variants</li>
              <li><strong>Markov chains</strong> ‚Äî Context depths 1-4, word and subword</li>
              <li><strong>Word embeddings</strong> ‚Äî 32, 64, 128 dimensions</li>
            </ul>
          </div>
        </div>

        <div class="pipeline-step">
          <div class="step-number">4</div>
          <div class="step-content">
            <h3>Evaluation & Ablation</h3>
            <p>
              Every model variant is evaluated on held-out test data. We compute comprehensive metrics
              and generate ablation studies comparing different configurations to identify optimal settings for each language.
            </p>
            <div class="step-details">
              <span class="detail-badge">Train/Test Split</span>
              <span class="detail-badge">Ablation Studies</span>
              <span class="detail-badge">Visualizations</span>
            </div>
          </div>
        </div>

        <div class="pipeline-step">
          <div class="step-number">5</div>
          <div class="step-content">
            <h3>Publishing to HuggingFace</h3>
            <p>
              All models, vocabularies, and evaluation reports are published to
              <a href="https://huggingface.co/wikilangs" target="_blank" rel="noopener">HuggingFace</a>.
              Each language repository includes model cards with metrics, visualizations, and usage examples.
            </p>
            <div class="step-details">
              <span class="detail-badge">Open Access</span>
              <span class="detail-badge">Model Cards</span>
              <span class="detail-badge">Ready to Use</span>
            </div>
          </div>
        </div>
      </div>

      <div class="resources-box">
        <h3>Learn More</h3>
        <div class="resource-links">
          <a href="https://huggingface.co/wikilangs" target="_blank" rel="noopener" class="resource-link">
            <span class="resource-icon">ü§ó</span>
            <span>HuggingFace Models</span>
          </a>
          <a href="https://huggingface.co/datasets/omarkamali/wikipedia-monthly" target="_blank" rel="noopener" class="resource-link">
            <span class="resource-icon">üìö</span>
            <span>Wikipedia Dataset</span>
          </a>
          <a href="https://github.com/wikilangs" target="_blank" rel="noopener" class="resource-link">
            <span class="resource-icon">üíª</span>
            <span>Source Code</span>
          </a>
        </div>
      </div>
    </div>
  </section>

  <!-- ====== PART 2: EVALUATION METHODOLOGY ====== -->
  <section class="section section-alt" id="evaluation">
    <div class="container">
      <div class="section-header">
        <span class="section-badge">Part 2</span>
        <h2>Evaluation Methodology</h2>
        <p class="section-subtitle">Understanding the metrics we use and how to interpret them</p>
      </div>
    </div>
  </section>

  <!-- Metrics Glossary -->
  <section class="section section-alt" id="metrics">
    <div class="container">
      <h3 class="metrics-main-header">Metrics Glossary</h3>

      <div class="metrics-section">
        <h4 class="metrics-category">Tokenizer Metrics</h4>

        <div class="metric-card">
          <h4>Compression Ratio</h4>
          <p class="metric-def">The ratio of characters to tokens (chars/token). Measures how efficiently the tokenizer represents text.</p>
          <p class="metric-intuition"><strong>Intuition:</strong> Higher compression means fewer tokens needed to represent the same text, reducing sequence lengths for downstream models. A 3x compression means ~3 characters per token on average.</p>
          <p class="metric-seek"><strong>What to seek:</strong> Higher is generally better for efficiency, but extremely high compression may indicate overly aggressive merging that loses morphological information.</p>
        </div>

        <div class="metric-card">
          <h4>Average Token Length (Fertility)</h4>
          <p class="metric-def">Mean number of characters per token produced by the tokenizer.</p>
          <p class="metric-intuition"><strong>Intuition:</strong> Longer tokens capture more context but may struggle with rare words; shorter tokens are more flexible but increase sequence length.</p>
          <p class="metric-seek"><strong>What to seek:</strong> Balance between 2-5 characters for most languages. Arabic and morphologically-rich languages may benefit from slightly longer tokens.</p>
        </div>

        <div class="metric-card">
          <h4>Unknown Token Rate (OOV Rate)</h4>
          <p class="metric-def">Percentage of tokens that map to the unknown/UNK token.</p>
          <p class="metric-intuition"><strong>Intuition:</strong> Lower OOV means better vocabulary coverage. High OOV indicates the tokenizer encounters many unseen character sequences.</p>
          <p class="metric-seek"><strong>What to seek:</strong> Below 1% is excellent; below 5% is acceptable. BPE tokenizers typically achieve very low OOV due to subword fallback.</p>
        </div>
      </div>

      <div class="metrics-section">
        <h4 class="metrics-category">N-gram Model Metrics</h4>

        <div class="metric-card">
          <h4>Perplexity</h4>
          <p class="metric-def">Measures how "surprised" the model is by test data. Mathematically: 2^(cross-entropy). Lower values indicate better prediction.</p>
          <p class="metric-intuition"><strong>Intuition:</strong> If perplexity is 100, the model is as uncertain as if choosing uniformly among 100 options at each step. A perplexity of 10 means effectively choosing among 10 equally likely options.</p>
          <p class="metric-seek"><strong>What to seek:</strong> Lower is better. Perplexity decreases with larger n-grams. Values vary widely by language and corpus size.</p>
        </div>

        <div class="metric-card">
          <h4>Entropy</h4>
          <p class="metric-def">Average information content (in bits) needed to encode the next token given the context. Related to perplexity: perplexity = 2^entropy.</p>
          <p class="metric-intuition"><strong>Intuition:</strong> High entropy means high uncertainty/randomness; low entropy means predictable patterns. Natural language typically has entropy between 1-4 bits per character.</p>
          <p class="metric-seek"><strong>What to seek:</strong> Lower entropy indicates more predictable text patterns. Entropy should decrease as n-gram size increases.</p>
        </div>

        <div class="metric-card">
          <h4>Coverage (Top-K)</h4>
          <p class="metric-def">Percentage of corpus occurrences explained by the top K most frequent n-grams.</p>
          <p class="metric-intuition"><strong>Intuition:</strong> High coverage with few patterns indicates repetitive/formulaic text; low coverage suggests diverse vocabulary usage.</p>
          <p class="metric-seek"><strong>What to seek:</strong> For language modeling, moderate coverage (40-60% with top-1000) is typical for natural text.</p>
        </div>
      </div>

      <div class="metrics-section">
        <h4 class="metrics-category">Markov Chain Metrics</h4>

        <div class="metric-card">
          <h4>Average Entropy</h4>
          <p class="metric-def">Mean entropy across all contexts, measuring average uncertainty in next-word prediction.</p>
          <p class="metric-intuition"><strong>Intuition:</strong> Lower entropy means the model is more confident about what comes next. Context-1 has high entropy; Context-4 has low entropy.</p>
          <p class="metric-seek"><strong>What to seek:</strong> Decreasing entropy with larger context sizes. Very low entropy (&lt;0.1) indicates highly deterministic transitions.</p>
        </div>

        <div class="metric-card">
          <h4>Branching Factor</h4>
          <p class="metric-def">Average number of unique next tokens observed for each context.</p>
          <p class="metric-intuition"><strong>Intuition:</strong> High branching = many possible continuations (flexible but uncertain); low branching = few options (predictable but potentially repetitive).</p>
          <p class="metric-seek"><strong>What to seek:</strong> Branching factor should decrease with context size. Values near 1.0 indicate nearly deterministic chains.</p>
        </div>

        <div class="metric-card">
          <h4>Predictability</h4>
          <p class="metric-def">Derived metric: (1 - normalized_entropy) x 100%. Indicates how deterministic the model's predictions are.</p>
          <p class="metric-intuition"><strong>Intuition:</strong> 100% means the next word is always certain; 0% means completely random.</p>
          <p class="metric-seek"><strong>What to seek:</strong> Higher predictability for text generation quality, but too high (&gt;98%) may produce repetitive output.</p>
        </div>
      </div>

      <div class="metrics-section">
        <h4 class="metrics-category">Vocabulary & Zipf's Law Metrics</h4>

        <div class="metric-card">
          <h4>Zipf's Coefficient</h4>
          <p class="metric-def">The slope of the log-log plot of word frequency vs. rank. Zipf's law predicts this should be approximately -1.</p>
          <p class="metric-intuition"><strong>Intuition:</strong> A coefficient near -1 indicates natural language patterns where a few words are very common and most words are rare.</p>
          <p class="metric-seek"><strong>What to seek:</strong> Values between -0.8 and -1.2 indicate healthy natural language distribution.</p>
        </div>

        <div class="metric-card">
          <h4>R¬≤ (Coefficient of Determination)</h4>
          <p class="metric-def">Measures how well the linear fit explains the frequency-rank relationship. Ranges from 0 to 1.</p>
          <p class="metric-intuition"><strong>Intuition:</strong> R¬≤ near 1.0 means the data closely follows Zipf's law.</p>
          <p class="metric-seek"><strong>What to seek:</strong> R¬≤ &gt; 0.95 is excellent; &gt; 0.99 indicates near-perfect Zipf adherence.</p>
        </div>
      </div>

      <div class="metrics-section">
        <h4 class="metrics-category">Word Embedding Metrics</h4>

        <div class="metric-card">
          <h4>Isotropy</h4>
          <p class="metric-def">Measures how uniformly distributed vectors are in the embedding space. Computed as the ratio of minimum to maximum singular values.</p>
          <p class="metric-intuition"><strong>Intuition:</strong> High isotropy (near 1.0) means vectors spread evenly in all directions; low isotropy means vectors cluster in certain directions.</p>
          <p class="metric-seek"><strong>What to seek:</strong> Higher isotropy generally indicates better-quality embeddings. Values &gt; 0.1 are reasonable; &gt; 0.3 is good.</p>
        </div>

        <div class="metric-card">
          <h4>Cosine Similarity</h4>
          <p class="metric-def">Measures angular similarity between vectors, ranging from -1 (opposite) to 1 (identical direction).</p>
          <p class="metric-intuition"><strong>Intuition:</strong> Words with similar meanings should have high cosine similarity.</p>
          <p class="metric-seek"><strong>What to seek:</strong> Semantically related words should score &gt; 0.5; synonyms often score &gt; 0.7.</p>
        </div>
      </div>
    </div>
  </section>

  <!-- Evaluation Methodology -->
  <section class="section" id="methodology">
    <div class="container">
      <h2>Evaluation Methodology</h2>

      <div class="method-grid">
        <div class="method-card">
          <h3>Data Source</h3>
          <p>
            All models are trained on <a href="https://huggingface.co/datasets/omarkamali/wikipedia-monthly" target="_blank" rel="noopener">wikipedia-monthly</a>,
            a regularly updated dataset containing Wikipedia articles across 300+ languages.
            We use monthly snapshots to ensure reproducibility.
          </p>
        </div>

        <div class="method-card">
          <h3>Train/Test Split</h3>
          <p>
            Each language's data is split into training and evaluation sets.
            Models are trained on the training set, and all metrics are computed on held-out test data.
          </p>
        </div>

        <div class="method-card">
          <h3>Ablation Studies</h3>
          <p>
            We systematically vary model hyperparameters (vocabulary size, n-gram size, context depth, embedding dimension)
            to provide comprehensive comparisons and recommendations for each language.
          </p>
        </div>

        <div class="method-card">
          <h3>Reproducibility</h3>
          <p>
            All training scripts, evaluation code, and raw results are available in our repositories.
            Each model card includes the exact date and configuration used for training.
          </p>
        </div>
      </div>
    </div>
  </section>

  <!-- Interpretation Guide -->
  <section class="section section-alt" id="interpretation">
    <div class="container">
      <h2>Interpretation Guidelines</h2>

      <div class="guidelines prose">
        <ol>
          <li><strong>Compare within model families:</strong> Metrics are most meaningful when comparing models of the same type (e.g., 8k vs 64k tokenizer).</li>
          <li><strong>Consider trade-offs:</strong> Better performance on one metric often comes at the cost of another (e.g., compression vs. OOV rate).</li>
          <li><strong>Context matters:</strong> Optimal values depend on downstream tasks. Text generation may prioritize different metrics than classification.</li>
          <li><strong>Corpus influence:</strong> All metrics are influenced by corpus characteristics. Wikipedia text differs from social media or literature.</li>
          <li><strong>Language-specific patterns:</strong> Morphologically rich languages (like Arabic) may show different optimal ranges than analytic languages.</li>
        </ol>
      </div>

      <div class="learn-more-box">
        <h3>Further Reading</h3>
        <p>Want to dive deeper into NLP evaluation? Here are some resources:</p>
        <div class="learn-links">
          <a href="https://en.wikipedia.org/wiki/Perplexity" target="_blank" rel="noopener" class="learn-link">
            <span>Perplexity</span>
            <small>Wikipedia</small>
          </a>
          <a href="https://en.wikipedia.org/wiki/Byte_pair_encoding" target="_blank" rel="noopener" class="learn-link">
            <span>BPE Tokenization</span>
            <small>Wikipedia</small>
          </a>
          <a href="https://en.wikipedia.org/wiki/Zipf%27s_law" target="_blank" rel="noopener" class="learn-link">
            <span>Zipf's Law</span>
            <small>Wikipedia</small>
          </a>
          <a href="https://en.wikipedia.org/wiki/Word_embedding" target="_blank" rel="noopener" class="learn-link">
            <span>Word Embeddings</span>
            <small>Wikipedia</small>
          </a>
          <a href="https://huggingface.co/learn/nlp-course" target="_blank" rel="noopener" class="learn-link">
            <span>NLP Course</span>
            <small>HuggingFace</small>
          </a>
        </div>
      </div>
    </div>
  </section>
</BaseLayout>

<style>
  .hero-compact {
    padding: var(--space-12) 0;
    background: var(--color-surface);
    border-bottom: 1px solid var(--color-border);
  }

  .hero-compact h1 {
    font-size: var(--font-size-4xl);
    margin-bottom: var(--space-4);
  }

  .hero-subtitle {
    font-size: var(--font-size-xl);
    color: var(--color-text-secondary);
  }

  /* Section Navigation */
  .section-nav {
    background: var(--color-surface);
    border-bottom: 1px solid var(--color-border);
    padding: var(--space-4) 0;
    position: sticky;
    top: 0;
    z-index: 10;
  }
  .section-nav .container {
    display: flex;
    gap: var(--space-4);
    justify-content: center;
  }
  .nav-link {
    display: flex;
    align-items: center;
    gap: var(--space-3);
    padding: var(--space-3) var(--space-5);
    background: var(--color-bg);
    border: 1px solid var(--color-border);
    border-radius: var(--radius-md);
    text-decoration: none;
    transition: all 0.2s;
  }
  .nav-link:hover {
    border-color: var(--color-accent);
    transform: translateY(-2px);
    box-shadow: 0 4px 12px rgba(0,0,0,0.08);
    text-decoration: none;
  }
  .nav-icon {
    font-size: 1.25rem;
  }
  .nav-link strong {
    display: block;
    color: var(--color-text);
  }
  .nav-link small {
    font-size: var(--font-size-sm);
    color: var(--color-text-muted);
  }

  /* Section Header */
  .section-header {
    text-align: center;
    margin-bottom: var(--space-10);
  }
  .section-badge {
    display: inline-block;
    background: var(--color-accent);
    color: white;
    font-size: var(--font-size-sm);
    font-weight: 600;
    padding: var(--space-1) var(--space-3);
    border-radius: var(--radius-full);
    margin-bottom: var(--space-3);
    text-transform: uppercase;
    letter-spacing: 0.05em;
  }
  .section-subtitle {
    font-size: var(--font-size-lg);
    color: var(--color-text-secondary);
    max-width: 600px;
    margin: 0 auto;
  }

  /* Pipeline Flow */
  .pipeline-flow {
    max-width: 800px;
    margin: 0 auto;
    position: relative;
  }
  .pipeline-flow::before {
    content: '';
    position: absolute;
    left: 20px;
    top: 40px;
    bottom: 40px;
    width: 2px;
    background: linear-gradient(180deg, var(--color-accent) 0%, var(--color-accent-dark, #6366f1) 100%);
    opacity: 0.3;
  }
  .pipeline-step {
    display: flex;
    gap: var(--space-5);
    margin-bottom: var(--space-6);
    position: relative;
  }
  .step-number {
    width: 42px;
    height: 42px;
    background: linear-gradient(135deg, var(--color-accent), var(--color-accent-dark, #6366f1));
    color: white;
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    font-weight: 700;
    font-size: var(--font-size-lg);
    flex-shrink: 0;
    position: relative;
    z-index: 1;
  }
  .step-content {
    flex: 1;
    background: var(--color-surface);
    border: 1px solid var(--color-border);
    border-radius: var(--radius-md);
    padding: var(--space-5);
  }
  .step-content h3 {
    font-size: var(--font-size-lg);
    margin-bottom: var(--space-2);
    color: var(--color-text);
  }
  .step-content p {
    color: var(--color-text-secondary);
    margin-bottom: var(--space-3);
  }
  .step-content a {
    color: var(--color-accent);
  }
  .step-details {
    display: flex;
    flex-wrap: wrap;
    gap: var(--space-2);
  }
  .detail-badge {
    font-size: var(--font-size-xs);
    background: var(--color-bg);
    color: var(--color-text-muted);
    padding: var(--space-1) var(--space-2);
    border-radius: var(--radius-sm);
  }
  .model-list {
    margin: var(--space-3) 0 0;
    padding-left: var(--space-5);
    color: var(--color-text-secondary);
  }
  .model-list li {
    margin-bottom: var(--space-2);
  }

  /* Resources Box */
  .resources-box {
    max-width: 800px;
    margin: var(--space-10) auto 0;
    background: var(--color-surface);
    border: 1px solid var(--color-border);
    border-radius: var(--radius-lg);
    padding: var(--space-6);
    text-align: center;
  }
  .resources-box h3 {
    font-size: var(--font-size-lg);
    margin-bottom: var(--space-4);
  }
  .resource-links {
    display: flex;
    gap: var(--space-4);
    justify-content: center;
    flex-wrap: wrap;
  }
  .resource-link {
    display: flex;
    align-items: center;
    gap: var(--space-2);
    padding: var(--space-3) var(--space-4);
    background: var(--color-bg);
    border: 1px solid var(--color-border);
    border-radius: var(--radius-md);
    text-decoration: none;
    color: var(--color-text);
    transition: all 0.2s;
  }
  .resource-link:hover {
    border-color: var(--color-accent);
    color: var(--color-accent);
    text-decoration: none;
    transform: translateY(-2px);
  }
  .resource-icon {
    font-size: 1.25rem;
  }

  h2 {
    font-size: var(--font-size-3xl);
    margin-bottom: var(--space-8);
  }

  .metrics-main-header {
    font-size: var(--font-size-2xl);
    margin-bottom: var(--space-8);
    color: var(--color-text);
  }

  .metrics-section {
    margin-bottom: var(--space-10);
  }

  .metrics-category {
    font-size: var(--font-size-xl);
    color: var(--color-accent);
    margin-bottom: var(--space-4);
    padding-bottom: var(--space-2);
    border-bottom: 2px solid var(--color-accent);
  }

  .metric-card {
    background: var(--color-bg);
    border-radius: var(--radius-md);
    padding: var(--space-5);
    margin-bottom: var(--space-4);
  }

  .metric-card h4 {
    font-size: var(--font-size-lg);
    margin-bottom: var(--space-3);
  }

  .metric-def {
    color: var(--color-text);
    margin-bottom: var(--space-3);
  }

  .metric-intuition,
  .metric-seek {
    font-size: var(--font-size-sm);
    color: var(--color-text-secondary);
    margin-bottom: var(--space-2);
  }

  .method-grid {
    display: grid;
    grid-template-columns: repeat(2, 1fr);
    gap: var(--space-6);
  }

  .method-card {
    background: var(--color-surface);
    border: 1px solid var(--color-border);
    border-radius: var(--radius-md);
    padding: var(--space-6);
  }

  .method-card h3 {
    font-size: var(--font-size-lg);
    margin-bottom: var(--space-3);
  }

  .method-card p {
    color: var(--color-text-secondary);
    margin: 0;
  }

  .guidelines ol {
    padding-left: var(--space-6);
  }

  .guidelines li {
    margin-bottom: var(--space-4);
    color: var(--color-text-secondary);
    line-height: var(--line-height-relaxed);
  }

  /* Learn More Box */
  .learn-more-box {
    margin-top: var(--space-10);
    background: var(--color-bg);
    border: 1px solid var(--color-border);
    border-radius: var(--radius-lg);
    padding: var(--space-6);
  }
  .learn-more-box h3 {
    font-size: var(--font-size-lg);
    margin-bottom: var(--space-2);
  }
  .learn-more-box > p {
    color: var(--color-text-secondary);
    margin-bottom: var(--space-4);
  }
  .learn-links {
    display: flex;
    flex-wrap: wrap;
    gap: var(--space-3);
  }
  .learn-link {
    display: flex;
    flex-direction: column;
    padding: var(--space-3) var(--space-4);
    background: var(--color-surface);
    border: 1px solid var(--color-border);
    border-radius: var(--radius-md);
    text-decoration: none;
    transition: all 0.2s;
    min-width: 120px;
  }
  .learn-link:hover {
    border-color: var(--color-accent);
    transform: translateY(-2px);
    text-decoration: none;
  }
  .learn-link span {
    color: var(--color-text);
    font-weight: 500;
  }
  .learn-link small {
    color: var(--color-text-muted);
    font-size: var(--font-size-xs);
  }

  @media (max-width: 768px) {
    .method-grid {
      grid-template-columns: 1fr;
    }
    .section-nav .container {
      flex-direction: column;
    }
  }
</style>
